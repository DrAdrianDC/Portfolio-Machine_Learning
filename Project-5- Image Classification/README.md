## Project-5 Image Classification 


This repository contains an in-depth comparison of three image classification techniques: Transfer Learning, Convolutional Neural Networks (CNNs), and XGBoost with features extracted from a pre-trained CNN. The comparison highlights the strengths and weaknesses of each approach based on their test accuracies.

#### Why Transfer Learning?

Transfer learning is a machine learning technique where a pre-trained model, originally trained on a large dataset for a specific task, is reused as the starting point for a model on a new, but related task. This approach leverages the knowledge gained from the original task to improve the performance on the new task.

Some advantages of Transfer Learning for Image Recognition are:
- Reduced Training Time
- Better Performance with Limited Data
- Easier Model Convergence
- Improved Accuracy




##### Main Objective
Compare Image Classification Techniques: Evaluate the effectiveness of Transfer Learning, Custom CNNs, and XGBoost with pre-trained CNN features to enhance the accuracy of image classification.

##### Expected Outcomes
* Accurate Image Classification: Achieve high levels of accuracy in classifying images, demonstrating the effectiveness of Transfer Learning

### Requirements 

    Python 3.8.3
    Pandas 2.0.3
    Numpy 1.21.0
    Scikit-learn 1.3.2
    Matplotlib 3.2.2
    Seaborn 0.10.1


### Dataset


The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.



### License
This project is licensed under the terms of the MIT license (See LICENSE.txt)
